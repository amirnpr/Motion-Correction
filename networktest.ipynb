{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Mount Google Drive and extract files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Path to the zip file\n",
    "zip_path = '/content/drive/MyDrive/mahak/mahak.zip'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/mahak')\n",
    "\n",
    "# Load images from DICOM files\n",
    "def load_images(patient_folder):\n",
    "    ct_images, pet_images = [], []\n",
    "    ct_folder = None\n",
    "    pet_folder = None\n",
    "\n",
    "    # Find CT and PET folders\n",
    "    for folder in os.listdir(patient_folder):\n",
    "        if 'CT' in folder:\n",
    "            ct_folder = os.path.join(patient_folder, folder)\n",
    "        elif 'PET' in folder:\n",
    "            pet_folder = os.path.join(patient_folder, folder)\n",
    "\n",
    "    # If CT or PET folder is not found, return empty arrays\n",
    "    if ct_folder is None or pet_folder is None:\n",
    "        print(f\"CT or PET folder not found for {patient_folder}\")\n",
    "        return np.array(ct_images), np.array(pet_images)\n",
    "\n",
    "    # Load images from found CT and PET folders\n",
    "    for filename in sorted(os.listdir(ct_folder)):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            ct_image_path = os.path.join(ct_folder, filename)\n",
    "            pet_image_path = os.path.join(pet_folder, filename)\n",
    "\n",
    "            ct_image = pydicom.dcmread(ct_image_path).pixel_array\n",
    "            pet_image = pydicom.dcmread(pet_image_path).pixel_array\n",
    "\n",
    "            # Resize images to 256x256\n",
    "            ct_image = resize(ct_image, (256, 256), anti_aliasing=True)\n",
    "            pet_image = resize(pet_image, (256, 256), anti_aliasing=True)\n",
    "\n",
    "            ct_images.append(ct_image)\n",
    "            pet_images.append(pet_image)\n",
    "\n",
    "    return np.array(ct_images), np.array(pet_images)\n",
    "\n",
    "# Load data for all patients\n",
    "patient_folders = [os.path.join('/content/mahak', folder) for folder in os.listdir('/content/mahak')]\n",
    "ct_data, pet_data = [], []\n",
    "for folder in patient_folders:\n",
    "    ct, pet = load_images(folder)\n",
    "    ct_data.append(ct)\n",
    "    pet_data.append(pet)\n",
    "\n",
    "# Convert to numpy arrays, filtering out empty arrays\n",
    "ct_data = np.concatenate([data for data in ct_data if data.size > 0], axis=0)\n",
    "pet_data = np.concatenate([data for data in pet_data if data.size > 0], axis=0)\n",
    "\n",
    "# Split into training and test sets\n",
    "ct_train, ct_test, pet_train, pet_test = train_test_split(ct_data, pet_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "ct_train = ct_train[..., np.newaxis] / 255.0\n",
    "pet_train = pet_train[..., np.newaxis] / 255.0\n",
    "ct_test = ct_test[..., np.newaxis] / 255.0\n",
    "pet_test = pet_test[..., np.newaxis] / 255.0\n",
    "\n",
    "# Data augmentation\n",
    "data_gen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=20)\n",
    "\n",
    "# Build U-Net model\n",
    "def unet_model(input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Down-sampling path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
    "\n",
    "    # Up-sampling path\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', padding='same')(u8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', padding='same')(u9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "model = unet_model(input_size=(256, 256, 1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train model with data augmentation\n",
    "model.fit(data_gen.flow(ct_train, pet_train, batch_size=4),\n",
    "          steps_per_epoch=len(ct_train) // 4,\n",
    "          epochs=10,\n",
    "          validation_data=(ct_test, pet_test))\n",
    "\n",
    "# Perform registration on the test set\n",
    "test_patient_index = 0  # Choose the first patient from the test set\n",
    "ct_test_patient = ct_test[test_patient_index]\n",
    "\n",
    "# Register each slice\n",
    "registered_images = []\n",
    "for slice_idx in range(ct_test_patient.shape[0]):\n",
    "    ct_slice = ct_test_patient[slice_idx][np.newaxis, ..., np.newaxis]  # Correct shape: (1, 256, 256, 1)\n",
    "    registered_image = model.predict(ct_slice)\n",
    "    registered_images.append(registered_image[0, ..., 0])\n",
    "\n",
    "# Save results\n",
    "save_folder = '/content/mahak/registration_results'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "for i, img in enumerate(registered_images):\n",
    "    plt.imsave(f\"{save_folder}/registered_slice_{i}.png\", img, cmap='gray')\n",
    "\n",
    "print(f\"Registration complete. Results saved in {save_folder}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
