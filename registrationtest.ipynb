{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CT and PET images.\n",
    "\n",
    "    Args:\n",
    "        Dataset (torch.utils.data.Dataset): Inherits from PyTorch Dataset class.\n",
    "\n",
    "    Attributes:\n",
    "        data (list): Contains tuples of CT and PET image tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patient_folders, target_size=(128, 128, 64)):\n",
    "        \"\"\"Initializes the MedicalDataset with CT and PET images.\n",
    "\n",
    "        Args:\n",
    "            patient_folders (list): List of patient folder paths.\n",
    "            target_size (tuple): Desired size for resizing images.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        for folder in patient_folders:\n",
    "            ct_folder = os.path.join(folder, 'ct')\n",
    "            pet_folder = os.path.join(folder, 'pet')\n",
    "            ct_images = [self.load_and_resize_image(os.path.join(ct_folder, img), target_size) for img in os.listdir(ct_folder)]\n",
    "            pet_images = [self.load_and_resize_image(os.path.join(pet_folder, img), target_size) for img in os.listdir(pet_folder)]\n",
    "            self.data.append((torch.tensor(ct_images, dtype=torch.float32), torch.tensor(pet_images, dtype=torch.float32)))\n",
    "\n",
    "    def load_and_resize_image(self, filepath, target_size):\n",
    "        \"\"\"Loads and resizes a DICOM image.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to the DICOM file.\n",
    "            target_size (tuple): Desired size for resizing.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Resized image array.\n",
    "        \"\"\"\n",
    "        image = sitk.ReadImage(filepath)\n",
    "        image_array = sitk.GetArrayFromImage(image)\n",
    "        resized_image = sitk.GetArrayFromImage(sitk.Resample(image, target_size))\n",
    "        return resized_image\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieves an item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the desired item.\n",
    "\n",
    "        Returns:\n",
    "            tuple: CT and PET images tensors.\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegistrationNet(nn.Module):\n",
    "    \"\"\"Simple Neural Network Model for image registration.\n",
    "\n",
    "    Args:\n",
    "        nn.Module: Inherits from PyTorch's neural network module.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv3d): First convolutional layer.\n",
    "        conv2 (nn.Conv3d): Second convolutional layer.\n",
    "        fc1 (nn.Linear): First fully connected layer.\n",
    "        fc2 (nn.Linear): Second fully connected layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the RegistrationNet model.\"\"\"\n",
    "        super(RegistrationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 128 * 128 * 64 // 4, 128)  # Adjust based on your input size\n",
    "        self.fc2 = nn.Linear(128, 6)  # 3 for translation and 3 for rotation\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with registration parameters.\n",
    "        \"\"\"\n",
    "        x = nn.functional.relu(self.conv1(x.unsqueeze(1)))  # Add channel dimension\n",
    "        x = nn.functional.max_pool3d(x, kernel_size=2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(patient_dirs, test_size=0.2):\n",
    "    \"\"\"Loads and splits the dataset into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        patient_dirs (list): List of patient directories.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader, DataLoader: Training and testing data loaders.\n",
    "    \"\"\"\n",
    "    dataset = MedicalDataset(patient_dirs)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(test_size * dataset_size))\n",
    "    test_indices = indices[:split]\n",
    "    train_indices = indices[split:]\n",
    "\n",
    "    train_data = DataLoader(dataset, batch_size=2, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
    "    test_data = DataLoader(dataset, batch_size=2, sampler=torch.utils.data.SubsetRandomSampler(test_indices))\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_folders = [f'/content/mahak/patient{i}' for i in range(1, 11)]\n",
    "train_loader, test_loader = load_data(patient_folders)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegistrationNet()\n",
    "criterion = nn.MSELoss()  # Placeholder for actual loss calculation\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for ct_images, pet_images in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ct_images)\n",
    "        loss = criterion(outputs, pet_images.view(-1, 6))  # Adjust based on your actual output\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Testing on a single patient\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for ct_images, pet_images in test_loader:\n",
    "        registration_params = model(ct_images)\n",
    "        print(\"Predicted Registration Parameters:\", registration_params)\n",
    "\n",
    "        # Transform the PET images for the test patient\n",
    "        transformed_pet_images = []\n",
    "        for i in range(len(pet_images)):\n",
    "            pet_image = sitk.GetImageFromArray(pet_images[i].numpy())\n",
    "\n",
    "            # Prepare the translation and rotation as a single list\n",
    "            translation = registration_params[i][:3].numpy().tolist()  # tx, ty, tz\n",
    "            rotation = registration_params[i][3:].numpy().tolist()      # rx, ry, rz\n",
    "\n",
    "            # Combine translation and rotation into a single list\n",
    "            transform_parameters = translation + rotation\n",
    "\n",
    "            # Create the transform with a single list\n",
    "            transform = sitk.Euler3DTransform(transform_parameters)\n",
    "\n",
    "            resampled_pet = sitk.Resample(\n",
    "                pet_image,\n",
    "                ct_images[i].numpy(),\n",
    "                transform,\n",
    "                sitk.sitkLinear,\n",
    "                0.0,\n",
    "                pet_image.GetPixelID()\n",
    "            )\n",
    "            transformed_pet_images.append(sitk.GetArrayFromImage(resampled_pet))\n",
    "\n",
    "        # Stack transformed images to create a single tensor\n",
    "        transformed_pet_images = torch.tensor(transformed_pet_images, dtype=torch.float32)\n",
    "\n",
    "        # Here you can save or visualize the transformed PET images\n",
    "        # Example: Save the first transformed image\n",
    "        output_path = '/content/transformed_pet_image.dcm'\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(transformed_pet_images[0].numpy()), output_path)\n",
    "\n",
    "print(\"Registration completed for test patient.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
